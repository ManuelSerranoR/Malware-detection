import pandas as pd
import glob
import gzip
import numpy as np

#Tokenizers
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
#Model selection
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
#Feature selection
from sklearn.feature_selection import mutual_info_classif
#Classifiers
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
#Metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
#Others
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
plt.switch_backend('agg')
import itertools
from collections import defaultdict
from sklearn.externals import joblib

data = pd.read_csv('fasttext_datasets/train_small.csv')

X_train = data['X']
Y_train = data['y']

print("Train dataset read\n")
CV = CountVectorizer(ngram_range=(1, 2))
TFIDF = TfidfVectorizer(ngram_range=(1, 2))
tokenizers = [CV, TFIDF]

#Define classification algorithms
clf_BernoulliNB = BernoulliNB()
clf_MultinomialNB = MultinomialNB()
clf_LR = LogisticRegression(C=10000,solver='saga',n_jobs=12)
clf_SVM = LinearSVC(class_weight="balanced", C=10000)
classifiers = [clf_BernoulliNB, clf_MultinomialNB, clf_LR, clf_SVM]

#Create models using pipelines of the above tokenizers and classifiers
models = {}
for t in tokenizers:
    for c in classifiers:
        models[str(t).split('(')[0]+str('_')+str(c).split('(')[0]] = Pipeline([('tokenizer', t), 
                                                                               ('classifier', c)])

#Fit models
for m in models:
    print("Fitting", m)
    models[m].fit(X_train, Y_train.tolist())
    joblib.dump(m, 'fasttext_results/'+m+'.pkl') 

print('testing time...')
data = pd.read_csv('fasttext_datasets/test_small.csv')
X_test = data['X']
Y_test = data['y']
# Now we store the results of accuracy, precision and recall:
accuracies = []
precisions = []
recalls = []
f1_scores = []

y_test_pred = {}
for m in models:
    print("Testing ", m)
    y_test_pred[m] = models[m].predict(X_test)
    accuracies.append(accuracy_score(Y_test.tolist(), y_test_pred[m]))
    precisions.append(precision_score(Y_test.tolist(), y_test_pred[m]))
    recalls.append(recall_score(Y_test.tolist(), y_test_pred[m]))
    f1_scores.append(f1_score(Y_test.tolist(), y_test_pred[m]))


indexes = [m for m in models]
print(indexes)
df_metrics = pd.DataFrame(data=np.transpose(np.array([accuracies, precisions, recalls, f1_scores])),
                          index=indexes,
                          columns=['Accuracy', 'Precision', 'Recall', 'F1 Score'])
df_metrics.to_csv('metrics_csv_new.csv', sep='\t')



def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    This code has been gotten from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

plt.figure(figsize=(15, 6))
for i, m in enumerate(models):
    cnf_matrix = confusion_matrix(Y_test.tolist(), y_test_pred[m])
    plt.subplot(241+i)
    plot_confusion_matrix(cnf_matrix, 
                          classes=["Bening", "Malware"],
                          title=m)
plt.savefig("fig2_new.png")
#plt.show()
